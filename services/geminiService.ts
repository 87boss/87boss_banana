
import { GoogleGenAI } from "@google/genai";
import type { GenerateContentResponse, Part } from "@google/genai";
import { GeneratedContent, CreativeIdea, SmartPlusConfig, BPField, BPAgentModel, ThirdPartyApiConfig, NanoBananaRequest, NanoBananaResponse, OpenAIChatRequest, OpenAIChatResponse } from '../types';

let ai: GoogleGenAI | null = null;

// è´è´APIé…ç½®å­˜å‚¨
let thirdPartyConfig: ThirdPartyApiConfig | null = null;

export const setThirdPartyConfig = (config: ThirdPartyApiConfig | null) => {
  thirdPartyConfig = config;
};

export const getThirdPartyConfig = (): ThirdPartyApiConfig | null => {
  return thirdPartyConfig;
};

export const initializeAiClient = (apiKey: string) => {
  if (!apiKey) {
    ai = null;
    console.warn("API Key removed. AI Client de-initialized.");
    return;
  }
  try {
    ai = new GoogleGenAI({ apiKey });
  } catch (e) {
    ai = null;
    const errorMessage = e instanceof Error ? e.message : 'An unknown error occurred.';
    console.error("Failed to initialize AI Client:", errorMessage);
    throw new Error(`Failed to initialize AI Client. Please check your API key. Error: ${errorMessage}`);
  }
};

const withRetry = async <T>(
  apiCall: () => Promise<T>,
  maxRetries = 3,
  initialDelay = 1000
): Promise<T> => {
  let lastError: unknown = new Error("Retry attempts failed.");
  let delay = initialDelay;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await apiCall();
    } catch (error) {
      lastError = error;
      const errorMessage = error instanceof Error ? error.message.toLowerCase() : String(error).toLowerCase();
      const isRetriable = errorMessage.includes('503') || errorMessage.includes('overloaded') || errorMessage.includes('unavailable');

      if (isRetriable && attempt < maxRetries) {
        console.warn(`Attempt ${attempt} failed with retriable error. Retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
        delay *= 2;
      } else {
        throw lastError;
      }
    }
  }
  throw lastError;
};

const fileToGenerativePart = async (file: File): Promise<Part> => {
  const base64EncodedDataPromise = new Promise<string>((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      if (reader.result && typeof reader.result === 'string') {
        const parts = reader.result.split(',');
        resolve(parts[1] || '');
      } else {
        reject(new Error('æ–‡ä»¶è¯»å–å¤±è´¥'));
      }
    };
    reader.onerror = () => reject(new Error('æ–‡ä»¶è¯»å–å‡ºé”™'));
    reader.readAsDataURL(file);
  });
  return {
    inlineData: {
      data: await base64EncodedDataPromise,
      mimeType: file.type,
    },
  };
};

export interface ImageEditConfig {
  aspectRatio: string;
  imageSize: string;
  seed?: number; // éšæœºç§å­ï¼Œç”¨äºé‡æ–°ç”Ÿæˆ
}

// å°†æ–‡ä»¶è½¬æ¢ä¸º base64
const fileToBase64 = async (file: File): Promise<string> => {
  return new Promise<string>((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      if (reader.result && typeof reader.result === 'string') {
        const parts = reader.result.split(',');
        resolve(parts[1] || '');
      } else {
        reject(new Error('æ–‡ä»¶è¯»å–å¤±è´¥'));
      }
    };
    reader.onerror = () => reject(new Error('æ–‡ä»¶è¯»å–å‡ºé”™'));
    reader.readAsDataURL(file);
  });
};

// å°† aspectRatio è½¬æ¢ä¸º Nano-banana æ”¯æŒçš„æ ¼å¼
const convertAspectRatio = (ratio: string): NanoBananaRequest['aspect_ratio'] | undefined => {
  const validRatios = ['4:3', '3:4', '16:9', '9:16', '2:3', '3:2', '1:1', '4:5', '5:4', '21:9'];
  if (ratio === 'Auto') {
    return undefined; // Auto æ¨¡å¼ä¸æŒ‡å®šæ¯”ä¾‹ï¼Œè®©APIæ ¹æ®è¾“å…¥å›¾ç‰‡å°ºå¯¸è‡ªåŠ¨å¤„ç†
  }
  if (!validRatios.includes(ratio)) {
    return '1:1'; // æ— æ•ˆæ¯”ä¾‹æ—¶ä½¿ç”¨ 1:1
  }
  return ratio as NanoBananaRequest['aspect_ratio'];
};

// è´è´APIå›¾ç‰‡ç”Ÿæˆ - æ”¯æŒæ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾ï¼ˆæ”¯æŒå¤šå›¾ï¼‰
// æœ¬åœ°ç‰ˆæœ¬ï¼šç›´æ¥è°ƒç”¨è´è´API
export const editImageWithThirdPartyApi = async (
  files: File[], // æ”¯æŒå¤šå›¾ï¼Œç©ºæ•°ç»„ä¸ºæ–‡ç”Ÿå›¾æ¨¡å¼
  prompt: string,
  config: ImageEditConfig,
  creativeIdeaCost?: number // åˆ›æ„åº“å®šä¹‰çš„æ‰£è´¹é‡‘é¢ï¼ˆæœ¬åœ°ç‰ˆä¸ç”¨ï¼‰
): Promise<GeneratedContent> => {
  if (!thirdPartyConfig || !thirdPartyConfig.enabled) {
    throw new Error("è´è´APIæœªå¯ç”¨");
  }

  // æœ¬åœ°ç‰ˆæœ¬ï¼šéœ€è¦å‰ç«¯é…ç½® API Key
  if (!thirdPartyConfig.apiKey) {
    throw new Error("è¯·å…ˆé…ç½®è´è´API Key");
  }
  if (!thirdPartyConfig.baseUrl) {
    throw new Error("è¯·å…ˆé…ç½®è´è´API Base URL");
  }

  // å¤„ç† Auto å®½é«˜æ¯”ï¼šå›¾ç”Ÿå›¾æ¨¡å¼ä¸‹ä¸ä¼  aspect_ratioï¼Œè®©APIæ ¹æ®è¾“å…¥å›¾ç‰‡å°ºå¯¸è‡ªåŠ¨ç”Ÿæˆ
  const isAutoAspectRatio = config.aspectRatio === 'Auto';
  const hasInputImage = files.length > 0;

  if (isAutoAspectRatio && hasInputImage) {
    console.log('[Autoå®½é«˜æ¯”] å›¾ç”Ÿå›¾æ¨¡å¼ï¼Œä¸æŒ‡å®šæ¯”ä¾‹ï¼Œä½¿ç”¨è¾“å…¥å›¾ç‰‡åŸå§‹å°ºå¯¸');
  }

  // æ„å»ºè¯·æ±‚ä½“ - Auto+å›¾ç”Ÿå›¾æ—¶å®Œå…¨ä¸åŒ…å« aspect_ratio å­—æ®µ
  const requestBody: NanoBananaRequest = {
    model: thirdPartyConfig.model || 'nano-banana-2',
    prompt: prompt,
    response_format: 'url',
    image_size: config.imageSize as '1K' | '2K' | '4K',
    seed: config.seed,
  };

  // åªæœ‰é Auto æˆ–æ–‡ç”Ÿå›¾æ¨¡å¼æ—¶æ‰æ·»åŠ  aspect_ratio
  if (!isAutoAspectRatio) {
    requestBody.aspect_ratio = convertAspectRatio(config.aspectRatio);
  } else if (!hasInputImage) {
    // æ–‡ç”Ÿå›¾ + Autoï¼šé»˜è®¤ä½¿ç”¨ 1:1
    requestBody.aspect_ratio = '1:1';
  }
  // å›¾ç”Ÿå›¾ + Autoï¼šä¸æ·»åŠ  aspect_ratio å­—æ®µï¼Œè®©APIä½¿ç”¨è¾“å…¥å›¾ç‰‡çš„åŸå§‹å°ºå¯¸

  // å¦‚æœæœ‰ä¸Šä¼ å›¾ç‰‡ï¼Œæ·»åŠ å‚è€ƒå›¾ï¼ˆå›¾ç”Ÿå›¾æ¨¡å¼ï¼Œæ”¯æŒå¤šå›¾ï¼‰
  if (files.length > 0) {
    const imagePromises = files.map(async (file) => {
      const imageBase64 = await fileToBase64(file);
      return `data:${file.type};base64,${imageBase64}`;
    });
    requestBody.image = await Promise.all(imagePromises);
  }

  // ç›´æ¥è°ƒç”¨è´è´API
  const url = `${thirdPartyConfig.baseUrl.replace(/\/$/, '')}/v1/images/generations`;

  const response = await withRetry(async () => {
    const res = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${thirdPartyConfig!.apiKey}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!res.ok) {
      const errorText = await res.text();
      throw new Error(`API è¯·æ±‚å¤±è´¥ (${res.status}): ${errorText}`);
    }

    return res.json() as Promise<NanoBananaResponse>;
  });

  // è§£æå“åº”
  const result: GeneratedContent = { text: null, imageUrl: null };

  if (response.error) {
    throw new Error(`API é”™è¯¯: ${response.error.message}`);
  }

  if (response.data && response.data.length > 0) {
    const imageData = response.data[0];
    if (imageData.url) {
      result.imageUrl = imageData.url;
    } else if (imageData.b64_json) {
      result.imageUrl = `data:image/png;base64,${imageData.b64_json}`;
    }
  }

  if (!result.imageUrl) {
    throw new Error("API æœªè¿”å›å›¾ç‰‡");
  }

  return result;
};

// è´è´APIæ–‡å­—å¤„ç†/å›¾ç‰‡åˆ†æ (Chat Completions)
// æœ¬åœ°ç‰ˆæœ¬ï¼šç›´æ¥è°ƒç”¨è´è´API
export const chatWithThirdPartyApi = async (
  systemPrompt: string,
  userMessage: string,
  imageFile?: File
): Promise<string> => {
  if (!thirdPartyConfig || !thirdPartyConfig.enabled) {
    throw new Error("è´è´APIæœªå¯ç”¨");
  }

  // æœ¬åœ°ç‰ˆæœ¬ï¼šéœ€è¦å‰ç«¯é…ç½® API Key
  if (!thirdPartyConfig.apiKey) {
    throw new Error("è¯·å…ˆé…ç½®è´è´API Key");
  }
  if (!thirdPartyConfig.baseUrl) {
    throw new Error("è¯·å…ˆé…ç½®è´è´API Base URL");
  }

  // æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹ - æ ¹æ®APIæ–‡æ¡£æ ¼å¼
  type ContentItem = { type: 'text'; text: string } | { type: 'image_url'; image_url: { url: string } };
  let userContent: string | ContentItem[];

  if (imageFile) {
    // åˆ†æå›¾ç‰‡æ—¶ï¼Œcontentéœ€è¦æ˜¯æ•°ç»„æ ¼å¼
    const imageBase64 = await fileToBase64(imageFile);
    const imageDataUrl = `data:${imageFile.type};base64,${imageBase64}`;
    userContent = [
      { type: 'text', text: userMessage },
      { type: 'image_url', image_url: { url: imageDataUrl } }
    ];
  } else {
    userContent = userMessage;
  }

  // ä½¿ç”¨é…ç½®çš„chatModelï¼Œé»˜è®¤ä½¿ç”¨ gemini-2.5-pro
  const chatModel = thirdPartyConfig.chatModel || 'gemini-2.5-pro';

  const requestBody: OpenAIChatRequest = {
    model: chatModel,
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userContent }
    ],
    max_tokens: 2000,
    temperature: 0.7,
    stream: false
  };

  // ç›´æ¥è°ƒç”¨è´è´API
  const url = `${thirdPartyConfig.baseUrl.replace(/\/$/, '')}/v1/chat/completions`;

  const response = await withRetry(async () => {
    const res = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        'Authorization': `Bearer ${thirdPartyConfig!.apiKey}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!res.ok) {
      const errorText = await res.text();
      throw new Error(`Chat API è¯·æ±‚å¤±è´¥ (${res.status}): ${errorText}`);
    }

    return res.json() as Promise<OpenAIChatResponse>;
  });

  if (response.choices && response.choices.length > 0) {
    return response.choices[0].message.content.trim();
  }

  throw new Error("Chat API æœªè¿”å›æœ‰æ•ˆå“åº”");
};

export const editImageWithGemini = async (files: File[], prompt: string, config: ImageEditConfig, creativeIdeaCost?: number): Promise<GeneratedContent> => {
  // å¦‚æœå¯ç”¨äº†è´è´APIï¼Œä½¿ç”¨è´è´API
  if (thirdPartyConfig && thirdPartyConfig.enabled) {
    return editImageWithThirdPartyApi(files, prompt, config, creativeIdeaCost);
  }

  if (!ai) {
    throw new Error("è¯·å…ˆè®¾ç½® Gemini API Key");
  }

  const model = 'gemini-3-pro-image-preview';

  if (!prompt) throw new Error("è¯·è¾“å…¥æç¤ºè¯");

  // æ„å»ºå†…å®¹ - æ”¯æŒæ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾ï¼ˆæ”¯æŒå¤šå›¾ï¼‰
  let contents;

  if (files.length > 0) {
    // å›¾ç”Ÿå›¾æ¨¡å¼ï¼ˆæ”¯æŒå¤šå›¾ï¼‰
    const imageParts = await Promise.all(files.map(file => fileToGenerativePart(file)));
    const instruction = files.length > 1
      ? 'è¯·æ ¹æ®ä»¥ä¸‹æç¤ºè¯ï¼Œå‚è€ƒæ‰€æœ‰è¾“å…¥å›¾ç‰‡è¿›è¡Œç¼–è¾‘/èåˆ/åˆ›ä½œï¼Œåªè¾“å‡ºç»“æœå›¾ç‰‡ï¼Œä¸è¦è¾“å‡ºä»»ä½•æ–‡å­—æè¿°ã€‚'
      : 'è¯·æ ¹æ®ä»¥ä¸‹æç¤ºè¯ç¼–è¾‘å›¾ç‰‡ï¼Œåªè¾“å‡ºç»“æœå›¾ç‰‡ï¼Œä¸è¦è¾“å‡ºä»»ä½•æ–‡å­—æè¿°ã€‚';
    const textPart: Part = { text: `${instruction}\n\n${prompt}` };
    contents = {
      parts: [...imageParts, textPart],
    };
  } else {
    // æ–‡ç”Ÿå›¾æ¨¡å¼
    const instruction = 'è¯·æ ¹æ®ä»¥ä¸‹æç¤ºè¯ç”Ÿæˆå›¾ç‰‡ï¼Œåªè¾“å‡ºç»“æœå›¾ç‰‡ï¼Œä¸è¦è¾“å‡ºä»»ä½•æ–‡å­—æè¿°ã€‚';
    const textPart: Part = { text: `${instruction}\n\n${prompt}` };
    contents = {
      parts: [textPart],
    };
  }

  // Configure image settings - TypeScript SDK ä½¿ç”¨ camelCase
  const imageConfig: any = {
    imageSize: config.imageSize,
    // æ³¨æ„ï¼šoutputMimeType åœ¨æŸäº› Gemini API ç‰ˆæœ¬ä¸­ä¸æ”¯æŒï¼Œç”± API è‡ªåŠ¨å†³å®šè¾“å‡ºæ ¼å¼
  };

  // å¤„ç† Auto å®½é«˜æ¯”ï¼šå›¾ç”Ÿå›¾æ¨¡å¼ä¸‹ä¸ä¼  aspectRatioï¼Œè®©APIæ ¹æ®è¾“å…¥å›¾ç‰‡å°ºå¯¸è‡ªåŠ¨ç”Ÿæˆ
  if (config.aspectRatio === 'Auto') {
    if (files.length > 0) {
      // å›¾ç”Ÿå›¾ + Autoï¼šä¸ä¼  aspectRatioï¼Œè®©Geminiä½¿ç”¨è¾“å…¥å›¾ç‰‡çš„åŸå§‹å°ºå¯¸
      console.log('[Gemini Autoå®½é«˜æ¯”] å›¾ç”Ÿå›¾æ¨¡å¼ï¼Œä¸æŒ‡å®šæ¯”ä¾‹ï¼Œä½¿ç”¨è¾“å…¥å›¾ç‰‡åŸå§‹å°ºå¯¸');
    }
    // æ–‡ç”Ÿå›¾ + Autoï¼šä¹Ÿä¸æŒ‡å®š aspectRatioï¼Œè®© Gemini è‡ªåŠ¨å¤„ç†
  } else {
    // ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†æ¯”ä¾‹
    imageConfig.aspectRatio = config.aspectRatio;
  }

  const response: GenerateContentResponse = await withRetry(() =>
    ai!.models.generateContent({
      model: model,
      contents: contents,
      config: {
        responseModalities: ['IMAGE', 'TEXT'],
        imageConfig: imageConfig
      },
    })
  );

  const result: GeneratedContent = { text: null, imageUrl: null };

  if (response.candidates?.[0]?.content?.parts) {
    for (const part of response.candidates[0].content.parts) {
      if (part.text) {
        result.text = (result.text || "") + part.text;
      } else if (part.inlineData) {
        const base64ImageBytes: string = part.inlineData.data;
        const mimeType = part.inlineData.mimeType;
        result.imageUrl = `data:${mimeType};base64,${base64ImageBytes}`;
        break;
      }
    }
  }

  if (!result.imageUrl) {
    const responseText = result.text || response.candidates?.[0]?.content?.parts?.map(p => p.text).join(' ') || "No text response.";
    throw new Error("API æœªè¿”å›å›¾ç‰‡ï¼Œå¯èƒ½æ‹’ç»äº†è¯·æ±‚ã€‚å“åº”: " + responseText);
  }

  return result;
};

// --- BP Agent Logic ---

// è´è´APIçš„BP Agentä»»åŠ¡ï¼ˆåˆ†æå›¾ç‰‡æˆ–çº¯æ–‡æœ¬ï¼‰
const runBPAgentTaskWithThirdParty = async (file: File | null, instruction: string): Promise<string> => {
  const systemInstruction = file
    ? `You are an AI analysis agent. 
Your task is to analyze the image based on the user's specific instruction and extract/generate the relevant information.
Output Rule: Return ONLY the result string. Do not include labels, markdown, or conversational filler. Keep it concise and suitable for use in an image generation prompt.`
    : `You are an AI creative agent.
Your task is to generate creative content based on the user's instruction.
Output Rule: Return ONLY the result string. Do not include labels, markdown, or conversational filler. Keep it concise and suitable for use in an image generation prompt.`;

  return chatWithThirdPartyApi(systemInstruction, instruction, file || undefined);
};

const runBPAgentTask = async (file: File | null, instruction: string, model: BPAgentModel): Promise<string> => {
  // å¦‚æœå¯ç”¨äº†è´è´APIï¼Œä½¿ç”¨è´è´Chat API
  if (thirdPartyConfig && thirdPartyConfig.enabled) {
    // æœ¬åœ°ç‰ˆæœ¬ï¼šæ£€æŸ¥æ˜¯å¦æœ‰API Key
    if (!thirdPartyConfig.apiKey) {
      throw new Error("è¯·å…ˆé…ç½®è´è´API Key");
    }
    return runBPAgentTaskWithThirdParty(file, instruction);
  }

  // ä½¿ç”¨ Gemini API
  if (!ai) throw new Error("è¯·å…ˆè®¾ç½® Gemini API Key æˆ–å¯ç”¨è´è´API");

  // æ„å»ºå†…å®¹éƒ¨åˆ†
  const parts: Part[] = [];

  // å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡éƒ¨åˆ†
  if (file) {
    const imagePart = await fileToGenerativePart(file);
    parts.push(imagePart);
  }

  // æ·»åŠ æ–‡æœ¬æŒ‡ä»¤
  parts.push({ text: instruction } as Part);

  // æ ¹æ®æ˜¯å¦æœ‰å›¾ç‰‡è°ƒæ•´ç³»ç»ŸæŒ‡ä»¤
  const systemInstruction = file
    ? `You are an AI analysis agent. 
    Your task is to analyze the image based on the user's specific instruction and extract/generate the relevant information.
    Output Rule: Return ONLY the result string. Do not include labels, markdown, or conversational filler. Keep it concise and suitable for use in an image generation prompt.`
    : `You are an AI creative agent.
    Your task is to generate creative content based on the user's instruction.
    Output Rule: Return ONLY the result string. Do not include labels, markdown, or conversational filler. Keep it concise and suitable for use in an image generation prompt.`;

  const response: GenerateContentResponse = await withRetry(() =>
    ai!.models.generateContent({
      model: model,
      contents: { parts },
      config: {
        systemInstruction: systemInstruction,
        temperature: 0.7,
      }
    })
  );

  const text = response.text;
  if (!text) return "";
  return text.trim();
};

export const processBPTemplate = async (
  file: File | null,
  templateIdea: CreativeIdea,
  userInputs: Record<string, string>
): Promise<string> => {
  console.log('[BP Template] å¼€å§‹å¤„ç†:', {
    title: templateIdea.title,
    hasBpFields: !!templateIdea.bpFields,
    fieldsCount: templateIdea.bpFields?.length || 0,
    agentCount: templateIdea.bpFields?.filter(f => f.type === 'agent').length || 0,
    hasFile: !!file,
    userInputs
  });

  if (!templateIdea.bpFields || templateIdea.bpFields.length === 0) {
    console.log('[BP Template] æ²¡æœ‰bpFieldsï¼Œè¿”å›åŸå§‹æç¤ºè¯');
    return templateIdea.prompt;
  }

  let finalPrompt = templateIdea.prompt;
  const fields = templateIdea.bpFields;

  // æ„å»ºå­—æ®µåç§°åˆ°IDçš„æ˜ å°„
  const nameToId: Record<string, string> = {};
  const nameToField: Record<string, typeof fields[0]> = {};
  fields.forEach(f => {
    nameToId[f.name] = f.id;
    nameToField[f.name] = f;
  });

  // è§£æAgentæŒ‡ä»¤ä¸­çš„ä¾èµ–
  const parseDependencies = (instruction: string): { inputs: string[], agents: string[] } => {
    const inputs: string[] = [];
    const agents: string[] = [];

    // åŒ¹é… /å˜é‡å (ç”¨æˆ·è¾“å…¥)
    const inputMatches = instruction.match(/\/([a-zA-Z_][a-zA-Z0-9_]*)/g);
    if (inputMatches) {
      inputMatches.forEach(match => {
        const name = match.slice(1); // ç§»é™¤ /
        if (nameToField[name]?.type === 'input') {
          inputs.push(name);
        }
      });
    }

    // åŒ¹é… {å˜é‡å} (Agentç»“æœ)
    const agentMatches = instruction.match(/\{([a-zA-Z_][a-zA-Z0-9_]*)\}/g);
    if (agentMatches) {
      agentMatches.forEach(match => {
        const name = match.slice(1, -1); // ç§»é™¤ { å’Œ }
        if (nameToField[name]?.type === 'agent') {
          agents.push(name);
        }
      });
    }

    return { inputs, agents };
  };

  // åˆ†ç±»Agentï¼šä¾èµ–å›¾ç‰‡çš„ vs çº¯æ–‡æœ¬åˆ†æçš„
  const agentFields = fields.filter(f => f.type === 'agent');
  const inputFields = fields.filter(f => f.type === 'input');

  // æ„å»ºä¾èµ–å›¾å¹¶è¿›è¡Œæ‹“æ‰‘æ’åº
  const agentDependencies: Record<string, { inputs: string[], agents: string[] }> = {};
  agentFields.forEach(agent => {
    if (agent.agentConfig) {
      agentDependencies[agent.name] = parseDependencies(agent.agentConfig.instruction);
    } else {
      agentDependencies[agent.name] = { inputs: [], agents: [] };
    }
  });

  // æ‹“æ‰‘æ’åºï¼šç¡®å®šAgentæ‰§è¡Œé¡ºåº
  const executionOrder: string[] = [];
  const visited = new Set<string>();
  const visiting = new Set<string>(); // ç”¨äºæ£€æµ‹å¾ªç¯ä¾èµ–

  const topologicalSort = (agentName: string): boolean => {
    if (visited.has(agentName)) return true;
    if (visiting.has(agentName)) {
      console.warn(`æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: ${agentName}`);
      return false; // å¾ªç¯ä¾èµ–
    }

    visiting.add(agentName);

    const deps = agentDependencies[agentName];
    if (deps) {
      // å…ˆå¤„ç†ä¾èµ–çš„Agent
      for (const depAgent of deps.agents) {
        if (!topologicalSort(depAgent)) {
          return false;
        }
      }
    }

    visiting.delete(agentName);
    visited.add(agentName);
    executionOrder.push(agentName);
    return true;
  };

  // å¯¹æ‰€æœ‰Agentè¿›è¡Œæ‹“æ‰‘æ’åº
  for (const agent of agentFields) {
    topologicalSort(agent.name);
  }

  // å­˜å‚¨ç»“æœ
  const agentResults: Record<string, string> = {};

  // æŒ‰é¡ºåºæ‰§è¡ŒAgent
  for (const agentName of executionOrder) {
    const field = nameToField[agentName];
    if (!field || field.type !== 'agent' || !field.agentConfig) continue;

    let instruction = field.agentConfig.instruction;

    // æ›¿æ¢æŒ‡ä»¤ä¸­çš„ç”¨æˆ·è¾“å…¥ /Name
    inputFields.forEach(inputField => {
      const val = userInputs[inputField.id] || '';
      instruction = instruction.split(`/${inputField.name}`).join(val);
    });

    // æ›¿æ¢æŒ‡ä»¤ä¸­å·²æ‰§è¡ŒAgentçš„ç»“æœ {Name}
    for (const [name, result] of Object.entries(agentResults)) {
      instruction = instruction.split(`{${name}}`).join(result);
    }

    // æ‰§è¡ŒAgent
    try {
      console.log(`[BP Agent] æ‰§è¡Œ ${agentName}...`);
      const result = await runBPAgentTask(file, instruction, field.agentConfig.model);
      console.log(`[BP Agent] ${agentName} å®Œæˆ`);
      agentResults[agentName] = result;
    } catch (e) {
      const errorMsg = e instanceof Error ? e.message : String(e);
      console.error(`[BP Agent] ${agentName} å¤±è´¥`);
      // æ˜¾ç¤ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      agentResults[agentName] = `[Agenté”™è¯¯: ${errorMsg}]`;
    }
  }

  // æ›¿æ¢æœ€ç»ˆæ¨¡æ¿ä¸­çš„Agentç»“æœ {Name}
  for (const [name, result] of Object.entries(agentResults)) {
    finalPrompt = finalPrompt.split(`{${name}}`).join(result);
  }

  // æ›¿æ¢æœ€ç»ˆæ¨¡æ¿ä¸­çš„ç”¨æˆ·è¾“å…¥ /Name
  inputFields.forEach(f => {
    const val = userInputs[f.id] || '';
    finalPrompt = finalPrompt.split(`/${f.name}`).join(val);
  });

  return finalPrompt;
};


// --- Legacy Smart Logic ---

const getSmartSystemInstruction = () => `You are a "Creative Prompt Fusion Specialist." Your goal is to merge a 'Modifier Keyword' into a 'Base Prompt' intelligently.

**Principles:**
1. **Base Prompt is Law**: Preserve the main subject and intent.
2. **Keyword is Adjective**: Treat it as a descriptive layer.
3. **Output**: ONLY the final prompt string. No explanations.`;

const getSmartPlusSystemInstruction = () => `You are a commercial **Art Director**. Synthesize a conceptual brief into a vivid scene description for a high-end product photoshoot.

**Output Rules:**
* Output ONLY the final prompt string.
* Single paragraph.
* Descriptive and professional. No markdown.`;


interface GeneratePromptParams {
  file: File;
  idea: CreativeIdea;
  keyword?: string; // For Smart
  smartPlusConfig?: SmartPlusConfig; // For Smart+
}


/**
 * Analyze interior image(s) to generate BIM data
 */
export const analyzeInteriorImage = async (
  imageData: string, // base64 without prefix
  mimeType: string = 'image/png',
  userDimensions?: { width?: number; height?: number; depth?: number }
): Promise<any> => { // Returns BIMData
  try {
    console.log('ğŸš€ [Gemini] Starting Interior Analysis...');
    const modelName = 'gemini-3-pro-image-preview'; // Standardized model

    if (!ai) {
      throw new Error("Gemini API Key is not configured. Please set it in Settings.");
    }

    // Schema Definition Prompt
    const schemaDefinition = `
export interface Dimensions { width: number; height: number; depth?: number; area?: number; }
export interface MaterialInfo { name: string; description?: string; estimatedCostPerUnit?: number; }
export type SurfaceType = 'wall' | 'floor' | 'ceiling' | 'window' | 'door' | 'partition';
export interface Surface { id: string; type: SurfaceType; material: MaterialInfo; dimensions: Dimensions; position?: string; }
export interface Furniture { id: string; name: string; category: string; dimensions?: Dimensions; position?: string; material?: string; estimatedPrice?: number; }

// Categories must be EXACTLY one of these 13 strings:
export type QuotationCategory = 
  | 'å¤©èŠ±æ¿' | 'ç‰†é¢' | 'é–€çª—' | 'åœ°é¢' | 'æ«ƒé«”' | 'ç‡ˆå…·' 
  | 'é–‹é—œæ’åº§' | 'é›»å™¨' | 'å®¶å…·' | 'è»Ÿè£' | 'æ‹†é™¤æ¸…é‹' | 'ä¿è­·å·¥ç¨‹' | 'å…¶ä»–';

export interface QuotationItem { 
  id: string; 
  category: QuotationCategory; 
  item: string; 
  description: string; 
  quantity: number; 
  unit: string; 
  unitPrice: number; 
  totalPrice: number; 
}
export interface SpaceInfo { roomType: string; dimensions: Dimensions; designStyle: string; }
export interface BIMData { space: SpaceInfo; surfaces: Surface[]; furniture: Furniture[]; estimatedQuotation: QuotationItem[]; totalEstimatedBudget: number; usageAnalysis: string; }
`;

    // Construct constraint string if dimensions are provided
    let constraintPrompt = "";
    if (userDimensions) {
      const constraints = [];
      if (userDimensions.depth) constraints.push(`Length/Depth: ${userDimensions.depth}m`);
      if (userDimensions.width) constraints.push(`Width: ${userDimensions.width}m`);
      if (userDimensions.height) constraints.push(`Height: ${userDimensions.height}m`);

      if (constraints.length > 0) {
        constraintPrompt = `
        **CRITICAL SPATIAL CONSTRAINTS (KNOWN GROUND TRUTH):**
        The user has provided the following ACTUAL dimensions for this space. You MUST use these values for your calculations.
        ${constraints.join('\n')}
        Scale all other objects (furniture, windows, etc.) relative to these known dimensions.
        `;
      }
    }

    const prompt = `
      You are an expert BIM (Building Information Modeling) Engineer, Interior Designer, and Quantity Surveyor.
      
      Task: 
      Analyze the provided interior image and reconstruct a detailed 3D understanding of the space.
      Identify all surfaces (walls, floor, ceiling), furniture, and materials.
      ${constraintPrompt ? constraintPrompt : "Estimate dimensions (in meters) based on standard furniture sizes (e.g., standard chair height ~0.45m)."}
      
      Generate a preliminary Quotation/Bill of Quantities (BoQ) for renovating this space provided in the image (or constructing it if it's a render).
      
      Output strictly valid JSON matching the following TypeScript interface (do not include markdown code blocks, just the raw JSON or wrapped in \`\`\`json):
      
      ${schemaDefinition}
      
      **CRITICAL INSTRUCTION: LANGUAGE**
      All text content (names, descriptions, categories, usage analysis, etc.) MUST be in **Traditional Chinese (Taiwan) / ç¹é«”ä¸­æ–‡(å°ç£)**.
      Only the JSON keys (e.g., "id", "type", "material", "dimensions") must remain in English as defined in the interface.
      
      **CRITICAL INSTRUCTION: CATEGORIES**
      You MUST strictly categorize every quotation item into one of the following 13 categories (and only these):
      1. å¤©èŠ±æ¿
      2. ç‰†é¢
      3. é–€çª—
      4. åœ°é¢
      5. æ«ƒé«”
      6. ç‡ˆå…·
      7. é–‹é—œæ’åº§
      8. é›»å™¨
      9. å®¶å…·
      10. è»Ÿè£
      11. æ‹†é™¤æ¸…é‹
      12. ä¿è­·å·¥ç¨‹
      13. å…¶ä»–
      
      Provide realistic market rates (in TWD - New Taiwan Dollar) for the quotation estimation.
      Ensure 'totalEstimatedBudget' is the sum of all 'totalPrice' in 'estimatedQuotation'.
    `;

    // ä½¿ç”¨æ–°çš„ SDK è¯­æ³• (GoogleGenAI v1+)
    const response: GenerateContentResponse = await withRetry(() =>
      ai!.models.generateContent({
        model: modelName,
        contents: [
          {
            parts: [
              { text: prompt },
              {
                inlineData: {
                  data: imageData,
                  mimeType: mimeType
                }
              }
            ]
          }
        ]
      })
    );

    let text = response.candidates?.[0]?.content?.parts?.[0]?.text;

    if (!text) {
      throw new Error('Gemini API returned no text response.');
    }

    // Clean up markdown
    text = text.replace(/```json\n?|\n?```/g, "").trim();

    try {
      const json = JSON.parse(text);
      console.log('âœ… [Gemini] BIM Analysis Complete');
      return json;
    } catch (e) {
      console.error('âŒ [Gemini] Failed to parse BIM JSON:', text);
      throw new Error('Failed to parse Gemini response as JSON');
    }

  } catch (error) {
    console.error('âŒ [Gemini] Interior Analysis Failed:', error);
    throw error;
  }
};


export const generateCreativePromptFromImage = async ({
  file,
  idea,
  keyword = '',
  smartPlusConfig,
}: GeneratePromptParams): Promise<string> => {
  // å¦‚æœå¯ç”¨äº†è´è´APIï¼Œä½¿ç”¨è´è´API
  const useThirdParty = thirdPartyConfig && thirdPartyConfig.enabled && thirdPartyConfig.apiKey;

  if (!useThirdParty && !ai) {
    throw new Error("è¯·å…ˆè®¾ç½® Gemini API Key æˆ–é…ç½®è´è´API");
  }

  const model = 'gemini-3-pro-image-preview';

  if (!file) throw new Error("è¯·ä¸Šä¼ å›¾ç‰‡");

  // If BP, use the new processor (should be called directly, but handling here for safety)
  if (idea.isBP) {
    throw new Error("BP Mode should use processBPTemplate directly.");
  }

  let systemInstruction = '';

  let userMessage = '';

  if (idea.isSmartPlus && smartPlusConfig) {
    // Smart+ Mode
    systemInstruction = getSmartPlusSystemInstruction();
    userMessage += `Story Brief:
"""
${idea.prompt}
"""

`;
    if (keyword.trim()) {
      userMessage += `Keywords:
"""
${keyword}
"""

`;
    }
    userMessage += `Key Elements:\n`;

    const templateConfig = idea.smartPlusConfig || [];

    templateConfig.forEach(templateComponent => {
      if (templateComponent.enabled) {
        const overrideComponent = smartPlusConfig.find(c => c.id === templateComponent.id);

        if (overrideComponent && overrideComponent.enabled) {
          const featureText = overrideComponent.features.trim() || 'Describe creatively based on the Story Brief';
          userMessage += `- ${overrideComponent.label}: ${featureText}\n`;
        } else {
          userMessage += `- ${templateComponent.label}: [GENERATE CREATIVELY]\n`;
        }
      }
    });
  } else {
    // Standard Smart Mode (Legacy support or simple mode)
    systemInstruction = getSmartSystemInstruction();
    userMessage += `Base Prompt:
"""
${idea.prompt}
"""

Modifier Keyword:
"""
${keyword}
"""

`;
  }

  userMessage += "\n\nNow, based on the provided image and all the rules, generate the final, synthesized prompt.";

  // ä½¿ç”¨è´è´APIè¿›è¡Œå›¾ç‰‡åˆ†æ
  if (useThirdParty) {
    return chatWithThirdPartyApi(systemInstruction, userMessage, file);
  }

  // ä½¿ç”¨ Gemini API
  const imagePart = await fileToGenerativePart(file);
  const textPart: Part = { text: userMessage };

  const contents = {
    parts: [imagePart, textPart],
  };

  const response: GenerateContentResponse = await withRetry(() =>
    ai!.models.generateContent({
      model: model,
      contents: contents,
      config: {
        systemInstruction: systemInstruction,
      },
    })
  );

  const resultText = response.text;

  if (!resultText) {
    throw new Error("API æœªè¿”å›æ–‡æœ¬å“åº”");
  }

  return resultText.trim();
};

/**
 * ä¼˜åŒ–æç¤ºè¯ - æ— åˆ›æ„åº“æ¨¡å¼
 * æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„ç®€å•æè¿°ï¼Œè®©æ¨¡å‹æ£æµ‹æ„å›¾å¹¶æ‰©å†™æˆæ›´å®Œæ•´çš„æç¤ºè¯
 */
export const optimizePrompt = async (userPrompt: string): Promise<string> => {
  // æ£€æŸ¥APIé…ç½®
  const useThirdParty = thirdPartyConfig && thirdPartyConfig.enabled && thirdPartyConfig.apiKey;

  if (!useThirdParty && !ai) {
    throw new Error("è¯·å…ˆè®¾ç½® Gemini API Key æˆ–é…ç½®è´è´API");
  }

  const model = 'gemini-3-pro-image-preview';

  const systemInstruction = `You are an expert AI image generation prompt engineer. Your task is to take a user's brief description or keywords and expand them into a detailed, high-quality image generation prompt.

Rules:
1. Understand the user's intent from their brief input
2. Expand the description with relevant details about:
   - Subject details and characteristics
   - Art style and visual aesthetic
   - Lighting and atmosphere
   - Composition and framing
   - Color palette and mood
3. Keep the expanded prompt focused and coherent
4. Output ONLY the optimized prompt text, no explanations
5. The output should be in the same language as the input
6. Keep output concise but descriptive (aim for 50-150 words)`;

  const userMessage = `Please optimize and expand this brief prompt into a detailed image generation prompt:

"""${userPrompt}"""

Output the optimized prompt directly:`;

  // ä½¿ç”¨è´è´API - ç›´æ¥å¤ç”¨ç°æœ‰å‡½æ•°ï¼Œä¸ä¼ å›¾ç‰‡
  if (useThirdParty) {
    return chatWithThirdPartyApi(systemInstruction, userMessage);
  }

  // ä½¿ç”¨ Gemini API
  const response: GenerateContentResponse = await withRetry(() =>
    ai!.models.generateContent({
      model: model,
      contents: { parts: [{ text: userMessage }] },
      config: {
        systemInstruction: systemInstruction,
      },
    })
  );

  const resultText = response.text;

  if (!resultText) {
    throw new Error("API æœªè¿”å›æ–‡æœ¬å“åº”");
  }

  return resultText.trim();
};

/**
 * åœ–ç‰‡åæ¨ - åˆ†æåœ–ç‰‡ä¸¦æå–é—œéµå­—èˆ‡è©³ç´°æç¤ºè©
 */
// å®¤å…§è¨­è¨ˆåæ¨è¦å‰‡
const INTERIOR_DESIGN_PROMPT = `
You are an expert Interior Design AI agent. Your task is to analyze the provided image and extract specific design details based on the following categories.

Checklist & Keywords to Extract:
1. Category: å¤©èŠ±æ¿ (Ceiling)
   - Check: Ceiling types, beams, moldings
   - Keywords ex: å¹³é‡˜å¤©èŠ±æ¿, é€ å‹å¤©èŠ±æ¿, è»Œé“ç‡ˆæºæ§½

2. Category: ç‰†é¢ (Walls)
   - Check: Wall materials, paint, panels
   - Keywords ex: å¤§ç†çŸ³ç‰†é¢, å¯¦æœ¨è²¼çš®, è—è¡“å¡—æ–™, æ¸…æ°´æ¨¡

3. Category: é–€çª— (Windows & Doors)
   - Check: Windows, doors, frames, glass
   - Keywords ex: è½åœ°çª—, é‹æ¡†æ‹‰é–€, ç™¾è‘‰çª—, é•·è™¹ç»ç’ƒ

4. Category: åœ°é¢ (Floor)
   - Check: Flooring materials, rugs
   - Keywords ex: è¶…è€ç£¨æœ¨åœ°æ¿, çŸ³è‹±ç£š, ç›¤å¤šç£¨, ç·¨ç¹”åœ°æ¯¯

5. Category: æ«ƒé«” (Cabinetry)
   - Check: Wardrobes, shelves, kitchen units
   - Keywords ex: ç³»çµ±è¡£æ«ƒ, ç»ç’ƒå±•ç¤ºæ«ƒ, ä¸­å³¶å§å°, é›»è¦–æ«ƒ

6. Category: å‚¢ä¿± (Furniture)
   - Check: Sofa, tables, chairs, beds
   - Keywords ex: Lå‹æ²™ç™¼, å¯¦æœ¨é¤æ¡Œ, å–®äººæ‰¶æ‰‹æ¤…, é›™äººåºŠæ¶

7. Category: å®¶é›»è¨­å‚™ (Appliances)
   - Check: Electronics, kitchen appliances
   - Keywords ex: å£æ›é›»è¦–, åµŒå…¥å¼çƒ¤ç®±, æ™ºæ…§å†°ç®±

8. Category: è»Ÿè£èˆ‡é£¾å“ (Decor)
   - Check: Curtains, art, plants, cushions
   - Keywords ex: è›‡å½¢ç°¾, æŠ½è±¡æ›ç•«, é¾œèƒŒèŠ‹, æŠ±æ•

9. Category: æè³ªèˆ‡è‰²å½© (Materials & Colors)
   - Check: Textures, color palette
   - Keywords ex: æ·ºæ©¡æœ¨, é»ƒéŠ…é‡‘å±¬, å¥¶èŒ¶è‰²ç³», è«è˜­è¿ªè‰²

10. Category: ç‡ˆå…· (Fixtures)
    - Check: Physical light fixtures (pendant, floor, recessed)
    - Keywords ex: ç·šæ€§åŠç‡ˆ, å´ç‡ˆ, è½åœ°ç‡ˆ, å£ç‡ˆ

11. Category: ç‡ˆå…‰æ°›åœ (Lighting Atmosphere)
    - Check: Light quality, temperature, shadows, natural light
    - Keywords ex: é–“æ¥ç…§æ˜, æš–ç™½å…‰ (3000K), è‡ªç„¶å…‰, é›»å½±æ„Ÿå…‰å½±

12. Category: å®¤å…§é¢¨æ ¼ (Interior Style)
    - Check: Overall design style, era
    - Keywords ex: ç¾ä»£ç°¡ç´„é¢¨, åŒ—æ­é¢¨, å·¥æ¥­é¢¨, æ—¥å¼ç„¡å°é¢¨

13. Category: æ”å½±é¡é ­ (Camera)
    - Check: Camera angle, focal length, depth of field
    - Keywords ex: å»£è§’é¡é ­, æ™¯æ·±æ•ˆæœ, æ­£è¦–åœ–, å»ºç¯‰æ”å½±

Output must be a valid JSON object with the following structure:
{
  "categories": [
    { "name": "å¤©èŠ±æ¿", "keywords": ["keyword1", "keyword2"] },
    { "name": "ç‰†é¢", "keywords": ["keyword1", "keyword2"] },
    ...
  ],
  "detailedPrompt": "A detailed, descriptive prompt..." // A professional interior design prompt incorporating the extracted details, in Traditional Chinese (ç¹é«”ä¸­æ–‡).
}

Rules:
1. Keywords must be in Traditional Chinese (ç¹é«”ä¸­æ–‡).
2. The detailedPrompt must be in Traditional Chinese (ç¹é«”ä¸­æ–‡).
3. Ensure strictly categorize keywords. If a category has no relevant details, leave keywords empty.
4. Respond ONLY with the JSON string.
`;

const GENERAL_PROMPT = `You are an expert AI image analysis agent. Your task is to analyze the provided image and extract relevant information.

Output must be a valid JSON object with the following structure:
{
  "categories": [
    { "name": "é€šç”¨é—œéµå­—", "keywords": ["keyword1", "keyword2", ...] } // Extract 15-20 distinctive visual keywords in Traditional Chinese.
  ],
  "detailedPrompt": "..." // A comprehensive prompt in Traditional Chinese.
}

Rules:
1. Keywords must be in Traditional Chinese (ç¹é«”ä¸­æ–‡).
2. The detailedPrompt must be in Traditional Chinese (ç¹é«”ä¸­æ–‡).
3. Respond ONLY with the JSON string.
`;

/**
 * åœ–ç‰‡åæ¨ - åˆ†æåœ–ç‰‡ä¸¦æå–é—œéµå­—èˆ‡è©³ç´°æç¤ºè©
 */
export const analyzeImageForPrompt = async (
  file: File,
  mode: 'general' | 'interior' = 'general'
): Promise<{ categories: { name: string; keywords: string[] }[]; detailedPrompt: string }> => {
  const useThirdParty = thirdPartyConfig && thirdPartyConfig.enabled && thirdPartyConfig.apiKey;

  if (!useThirdParty && !ai) {
    throw new Error("è«‹å…ˆè¨­ç½® Gemini API Key æˆ–é…ç½®è²è´API");
  }

  // ä½¿ç”¨ Gemini 3 Pro Image Preview (å…¨èƒ½å¤šæ¨¡æ…‹)
  const model = 'gemini-3-pro-image-preview';

  const systemInstruction = mode === 'interior' ? INTERIOR_DESIGN_PROMPT : GENERAL_PROMPT;

  const userMessage = "Analyze this image and provide categorized keywords and a detailed prompt in JSON format. OUTPUT MUST BE IN TRADITIONAL CHINESE.";

  let resultText = '';

  try {
    if (useThirdParty) {
      resultText = await chatWithThirdPartyApi(systemInstruction, userMessage, file);
    } else {
      const imagePart = await fileToGenerativePart(file);
      const response = await withRetry(() =>
        ai!.models.generateContent({
          model: model,
          contents: {
            parts: [imagePart, { text: userMessage }]
          },
          config: {
            systemInstruction: systemInstruction,
            responseMimeType: 'application/json', // ç¢ºä¿è¿”å› JSON
          },
        })
      );
      resultText = response.text || '';
    }

    // æ¸…ç†å¯èƒ½åŒ…å«çš„ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
    const jsonStr = resultText.replace(/```json\n?|\n?```/g, '').trim();

    const result = JSON.parse(jsonStr);

    // å…¼å®¹èˆŠæ ¼å¼ (å¦‚æœAIè¿”å›äº†èˆŠæ ¼å¼)
    let categories: { name: string; keywords: string[] }[] = [];
    if (Array.isArray(result.categories)) {
      categories = result.categories;
    } else if (Array.isArray(result.keywords)) {
      // èˆŠç‰ˆå›å‚³æ ¼å¼ Array of strings
      categories = [{ name: 'é—œéµå­—', keywords: result.keywords }];
    } else if (typeof result.keywords === 'object') {
      // èˆŠç‰ˆå›å‚³æ ¼å¼ Object (key: []string)
      categories = Object.entries(result.keywords).map(([name, kws]) => ({
        name,
        keywords: Array.isArray(kws) ? (kws as string[]) : []
      }));
    }

    return {
      categories: categories,
      detailedPrompt: typeof result.detailedPrompt === 'string' ? result.detailedPrompt : ''
    };
  } catch (error) {
    console.error("Image analysis failed:", error);
    throw new Error("ç„¡æ³•åˆ†æåœ–ç‰‡ï¼Œè«‹ç¨å¾Œå†è©¦");
  }
};

/**
 * Generate a technical engineering/construction drawing for a specific item
 */
export const generateEngineeringDrawing = async (
  originalImageBase64: string,
  itemDescription: string,
  userCommand?: string
): Promise<string> => {
  if (!ai && !(thirdPartyConfig && thirdPartyConfig.enabled)) {
    throw new Error("AI Service not configured");
  }

  // Convert base64 to File object for the editImageWithGemini function
  const cleanBase64 = originalImageBase64.replace(/^data:image\/\w+;base64,/, "");
  const byteCharacters = atob(cleanBase64);
  const byteNumbers = new Array(byteCharacters.length);
  for (let i = 0; i < byteCharacters.length; i++) {
    byteNumbers[i] = byteCharacters.charCodeAt(i);
  }
  const byteArray = new Uint8Array(byteNumbers);
  const blob = new Blob([byteArray], { type: 'image/png' }); // Default to png
  const file = new File([blob], "original_context.png", { type: 'image/png' });

  const prompt = `
    Generate a professional technical construction drawing (CAD style engineering drawing) for the following item:
    "${itemDescription}"
    
    Context:
    This item fits within the interior space shown in the input image.
    
    Style Requirements:
    - 2D Technical Drawing (Elevation or Section view).
    - Black lines on white background (Blueprint or CAD style).
    - Include technical annotations and dimension lines (mock values are fine if exact are unknown, but make them realistic).
    - Clean, precise lines.
    - Aspect Ratio: 2:3 (Vertical).
    
    ${userCommand ? `Additional User Command: ${userCommand}` : ''}
    
    The output must strictly be the engineering drawing image only.
  `;

  // Use editImageWithGemini which handles Img2Img
  const result = await editImageWithGemini(
    [file],
    prompt,
    {
      aspectRatio: '2:3',
      imageSize: '1K', // 2K might be too slow/expensive, start with 1K or map to appropriate sizing
    }
  );

  if (!result.imageUrl) {
    throw new Error("Failed to generate engineering drawing");
  }

  return result.imageUrl;
};

export const generateCoverPrompts = async (
  theme: string,
  title: string,
  subtitle: string,
  footer: string,
  textEffect: string,
  count: number,
  scene: string,
  plot: string,
  media: string,
  apiKey?: string,
  thirdPartyConfig?: ThirdPartyApiConfig
): Promise<string[]> => {
  // Check logic matching generateCreativePromptFromImage
  const useThirdParty = thirdPartyConfig && thirdPartyConfig.enabled && thirdPartyConfig.apiKey;
  if (!useThirdParty && !ai) {
    throw new Error("è«‹å…ˆè¨­ç½® Gemini API Key æˆ–é…ç½®è²è´API");
  }

  const modelName = 'gemini-3-pro-image-preview'; // Matching user request/reference

  // Dynamic check for text constraints
  const hasTitle = title && title.trim().length > 0;
  const hasSubtitle = subtitle && subtitle.trim().length > 0;
  const hasFooter = footer && footer.trim().length > 0;

  const titleInstruction = hasTitle
    ? `- Main Title: "${title}"`
    : `- Main Title: [NONE] (Do NOT include any title text)`;

  const subtitleInstruction = hasSubtitle
    ? `- Subtitle: "${subtitle}"`
    : `- Subtitle: [NONE] (Do NOT include any subtitle text)`;

  const footerInstruction = hasFooter
    ? `- Footer text: "${footer}"`
    : `- Footer text: [NONE] (Do NOT include any footer text)`;

  // Build the text rendering instruction dynamically
  let textRenderingInstruction = `5. **CRITICAL: TEXT RENDERING**: `;
  if (!hasTitle && !hasSubtitle && !hasFooter) {
    textRenderingInstruction += `You MUST explicitly instruct the image generator NOT to render any text. The image should be text-free.`;
  } else {
    textRenderingInstruction += `You MUST explicitly instruct the image generator to RENDER the text ONLY if provided:\n`;
    if (hasTitle) {
      textRenderingInstruction += `   - **Title**: Include "${title}" written in bold typography. Apply the "${textEffect}" effect if applicable.\n`;
    } else {
      textRenderingInstruction += `   - **Title**: Do NOT include any main title text.\n`;
    }

    if (hasSubtitle) {
      textRenderingInstruction += `   - **Subtitle**: Include "${subtitle}" in smaller font.\n`;
    }

    if (hasFooter) {
      textRenderingInstruction += `   - **Footer**: Include "${footer}" at the bottom.\n`;
    }
  }

  // Handle "Random" style logic
  let styleInstruction = `3. **Magazine Style**: The user has selected the magazine style "${media}". Ensure the generated image strictly follows the aesthetic, layout, and visual language of this specific magazine.`;
  if (media === 'Random Magazine Style') {
    styleInstruction = `3. **Magazine Style**: You MUST randomly check a high-end magazine style (e.g. Vogue, Kinfolk, Time, Brutus, etc.) for EACH prompt. Ensure every prompt has a DIFFERENT, distinct magazine style.`;
  }

  const systemPrompt = `You are an expert AI Art Director specializing in HIGH-END MAGAZINE COVER design.
Your task is to generate ${count} distinct, high-quality AI image prompts based on the following metadata:
- Theme/Style/Context: "${theme}"
- Magazine Style: "${media}"
${titleInstruction}
${subtitleInstruction}
${footerInstruction}
- Text Effect: "${textEffect}"

Guidelines:
1. Each prompt must describe a **MAGAZINE COVER VISUAL**.
2. Incorporate the "Theme" into the visual style.
${styleInstruction}
4. **NO SOCIAL MEDIA BIAS**: Do NOT mention "Instagram", "Social Media", "Post", "Feed", or "Like". This is a MAGAZINE COVER, not a social post.
${textRenderingInstruction}
6. Provide variety in composition (close-up, wide shot, centralized).
7. **LANGUAGE**: The Output Prompts MUST be in **Traditional Chinese (ç¹é«”ä¸­æ–‡)**.
8. Return ONLY a valid JSON array of strings. No markdown, no "Here are...".
Example output: ["ä¸€å¼µå……æ»¿ VOGUE æ™‚å°šæ„Ÿçš„å°é¢ï¼Œæ¨¡ç‰¹å…’èº«ç©¿...", "å¾©å¤ TIME é›œèªŒé¢¨æ ¼çš„è¨­è¨ˆï¼Œå¼·èª¿..."]`;

  try {
    let resultText = '';

    // 1. Third Party Path
    if (useThirdParty) {
      console.log('[Cover] Generating with Third Party API...', { model: thirdPartyConfig!.chatModel });
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 30000); // 30s timeout

      try {
        const response = await fetch(`${thirdPartyConfig!.baseUrl}/v1/chat/completions`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${thirdPartyConfig!.apiKey}`
          },
          body: JSON.stringify({
            model: thirdPartyConfig!.chatModel || 'gemini-2.0-flash-exp',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: `Generate ${count} prompts.` }
            ],
            temperature: 0.7
          }),
          signal: controller.signal
        });
        clearTimeout(timeoutId);

        if (!response.ok) {
          const errText = await response.text();
          console.error('[ThirdParty API Error]', response.status, errText);
          throw new Error(`ThirdParty API failed (${response.status}): ${errText}`);
        }
        const data = await response.json();
        resultText = data.choices[0].message.content;
      } catch (e: any) {
        clearTimeout(timeoutId);
        if (e.name === 'AbortError') {
          throw new Error('Request timed out (30s)');
        }
        throw e;
      }

    } else {
      // 2. Local Gemini Path (using SDK + 3 Pro)
      const response: GenerateContentResponse = await withRetry(() =>
        ai!.models.generateContent({
          model: modelName,
          contents: [
            {
              parts: [
                { text: systemPrompt + "\n\nGenerate the prompts." }
              ]
            }
          ],
          config: {
            temperature: 0.7
          }
        })
      );

      resultText = response.candidates?.[0]?.content?.parts?.[0]?.text || '';
      if (!resultText) {
        throw new Error('Gemini API returned no text response.');
      }
    }

    // Clean up markdown block if present
    const jsonStr = resultText.replace(/```json/g, '').replace(/```/g, '').trim();
    const prompts = JSON.parse(jsonStr);

    if (Array.isArray(prompts)) {
      return prompts.slice(0, count);
    }
    return [];

  } catch (error) {
    console.error("Cover Prompt Generation Failed:", error);
    throw error;
  }
};

/**
 * ç¿»è­¯æ–‡æœ¬åˆ°ç¹é«”ä¸­æ–‡
 */
export const translateText = async (text: string): Promise<string> => {
  const useThirdParty = thirdPartyConfig && thirdPartyConfig.enabled && thirdPartyConfig.apiKey;

  // Auto-initialize if needed
  if (!useThirdParty && !ai) {
    const savedKey = localStorage.getItem('gemini_api_key');
    if (savedKey) {
      initializeAiClient(savedKey);
    }
  }

  if (!useThirdParty && !ai) {
    console.warn("AI service not ready for translation, returning original text.");
    return text;
  }

  // Simple check if text is already likely Chinese (contains Chinese characters)
  if (/[\u4e00-\u9fa5]/.test(text)) {
    return text;
  }

  const systemPrompt = `You are a professional translator. Translate the following text into Traditional Chinese (Taiwan).
  - Output ONLY the translated text.
  - Keep IT terms or specific brand names in English if appropriate, or provide standard translations.
  - Be concise.`;

  try {
    let resultText = '';
    if (useThirdParty) {
      resultText = await chatWithThirdPartyApi(systemPrompt, text);
    } else {
      const model = 'gemini-2.0-flash-exp'; // Fast model for translation
      const response = await withRetry(() =>
        ai!.models.generateContent({
          model: model,
          contents: { parts: [{ text: `Translate to Traditional Chinese: ${text}` }] },
          config: { systemInstruction: systemPrompt },
        })
      );
      resultText = response.text || text;
    }
    return resultText.trim();
  } catch (error) {
    console.error("Translation failed:", error);
    return text;
  }
};


